services:
  paddleocr-vl-api:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-vl:latest
    container_name: paddleocr-vl-api
    volumes:
      - /root/.paddleocr:/home/paddleocr/.paddleocr
      - /root/.paddlex:/home/paddleocr/.paddlex
      - ./PaddleOCR-VL.yaml:/home/paddleocr/pipeline_config.yaml:ro
    ports:
      - 8080:8080
    depends_on:
      paddleocr-genai-vllm-server:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/health || exit 1" ]

  paddleocr-genai-vllm-server:
    image: ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddleocr-genai-vllm-server:latest
    container_name: paddleocr-genai-vllm-server
    command: [ "paddleocr", "genai_server", "--model_name", "PaddleOCR-VL-0.9B", "--host", "0.0.0.0", "--port", "8080", "--backend", "vllm", "--backend_config", "vllm_config.yaml" ]
    volumes:
      - /root/.paddleocr:/home/paddleocr/.paddleocr
      - /root/.paddlex:/home/paddleocr/.paddlex
      - ./vllm_config.yaml:/home/paddleocr/vllm_config.yaml:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/health || exit 1" ]
      start_period: 300s
